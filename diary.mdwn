# Diary of a site conversion

## Write an automated conversion tool that solves enough of the problem

`ikiwiki-import` works in a way I trust and handles most of the
tedium, letting me start benefiting from the ikiwiki way (edit some
files, rebuild, commit if it's good) while I look after the remaining
details. (It would be nice if `ikiwiki-import` left me even less
to do.)

`ikiwiki-import-check` helps me believe that `ikiwiki-import`
performed an accurate and complete import of my data. (It would be
nice if `ikiwiki-import-check` gave me even more confidence.)

I'm coming from Textpattern (a MySQL-backed CMS), but `ikiwiki-import`
can easily be extended to handle your data source.

## Prevent the soon-to-be-old site from being changed

In my case, I created a MySQL user with read-only privileges to my
site's database:

    :myserver; mysql> CREATE USER 'schmonz_txp_ro'@'localhost' IDENTIFIED BY 'XXX';
    :myserver; mysql> GRANT SELECT ON schmonz_textpattern.* TO 'schmonz_txp_ro'@'localhost';

I edited `textpattern/textpattern/config.php` to connect via this
read-only user instead. No new visitor logs get written, the site
still works, etc.

## Make a local copy of the source to be imported

In my case, Textpattern's database:

    :myserver; mysqldump -u schmonz -p --databases schmonz_textpattern > source.sql
    :mylaptop; mysql -u schmonz -p < source.sql
    :mylaptop; mysql XXX-remove-database-password

XXX and maybe `config.php`

## Run the tool locally

    :mylaptop; SRCDIR=`pwd`/aftersrc
    :mylaptop; ./bin/ikiwiki-import $SRCDIR verysmall.setup textpattern dbname schmonz_textpattern user schmonz

## Do basic sanity-checking

Does `find $SRCDIR -type f | wc -l` produce the number of posts
and comments (combined) that you're expecting?

## Try browsing around

    :mylaptop; DESTDIR=`pwd`/afterhtml
    :mylaptop; ikiwiki $SRCDIR $DESTDIR -verbose -plugin sidebar -plugin theme -plugin inline -plugin trail -plugin textile -plugin tag -plugin comments -set comments_pagespec='*' -set comments_allowauthor=1 -set allow_symlinks_before_srcdir=1 -set libdir='../ikiwiki' -set wikiname='Amitai Schlair' --setup verysmall.setup --dumpsetup after.setup
    :mylaptop; ikiwiki --setup after.setup --rebuild

- Point a webserver at `$DESTDIR` so you can browse easily (because
  `usedirs: 1`, the default, means lots of `subdir/index.html`)
- Point your browser at the webserver and spot-check what you're seeing

If this gives you enough confidence, you can stop here. I kept going.

## Get a local mirror of your soon-to-be-old site

Assuming the site you're importing is still live, web-crawl a static
copy:

    :mylaptop; wget --mirror -p --html-extension http://www.schmonz.com
    :mylaptop; mv www.schmonz.com beforehtml
    :mylaptop; STATICMIRROR=beforehtml

Find and remove (or move aside) anything that isn't your content --
index pages, archive pages, CSS, etc.:

    :mylaptop; cd $STATICMIRROR
    :mylaptop; find . -type f -name '*\?*' # turns up some stuff
    :mylaptop; rm index.html\?.html index.html\?pg=*.html category/*/index.html\?pg=*.html ./2003/12/19/planworld-2003-12-19\?.html css.php\?n=*.css atom/index.html\?*=* rss/index.html\?*=*
    :mylaptop; find . -type f -name '*\?*' # turns up nothing

(You may want to keep these files off to the side, so you can
consult them when you reimplement them with ikiwiki.)

`wget` will have downloaded the permalink `/foo` as `/foo.html`,
which matches neither your live site nor ikiwiki's default behavior.
Put this in `usedirify` (and `chmod +x` it):

    #!/bin/sh
    `_BASENAME=$(basename $1 .html)`
    `mkdir ${_BASENAME} && mv ${_BASENAME}.html ${_BASENAME}/index.html && echo ${_BASENAME}/index.html`

Postprocess the mirrored permalinks with it:

    :mylaptop; find . -type f -name '*.html' -a ! -name index.html -execdir /path/to/usedirify {} \;

## Do more thorough sanity-checking

For every page in `$STATICMIRROR`, diff against the corresponding
page in `$DESTDIR` (or complain if it doesn't exist):

    :mylaptop; ( cd $STATICMIRROR && for i in $(echo [[:digit:]]*); do find $i -type f | sed -e 's|/index.html$||'; done ) | xargs ./bin/ikiwiki-import-check

And vice versa:

    :mylaptop; ( cd $DESTDIR && for i in $(echo [[:digit:]]*); do find $i -type f | sed -e 's|/index.html$||'; done ) | xargs ./bin/ikiwiki-import-check

Since HTML from different sources won't diff cleanly, you'll have
to inspect the diffs and decide whether they're unimportant (such
as the same words line-wrapped differently) or important (such as
missing or wrongly encoded text). Tweak the import code and/or
twiddle `after.setup` until you're convinced nothing much important
is wrong.

Congratulations! Your content has been imported into `$SRCDIR`.

## Put `$SRCDIR` in revision control

Your content's ready, but you'll probably need to do a few more
things before your site's ready. Now's a good time to run
`ikiwiki-makerepo`, or at least `git init` (and add and commit
everything).

## Add any out-of-band content

Textpattern doesn't store images or other media in its database,
just references to where they're stored on the host filesystem.  I
didn't teach the importer to chase those references and fetch those
files, but that's okay, I can yoink them from my static mirror:

    :mylaptop; cp -R $STATICMIRROR/images $SRCDIR
    :mylaptop; cp -R $STATICMIRROR/file_download $SRCDIR

Add and commit.

## Compose, arrange, and style your new ikiwiki site

Every published post and comment from my Textpattern site is accounted
for, but my ikiwiki site still has the default front page. I put
an `inline` directive in `$SRCDIR/index.mdwn` and the front page
started looking better. I copied part of a Textpattern template to
`$SRCDIR/sidebar.mdwn`, converting it to idiomatic Markdown with
WikiLinks, and things looked better still. I might try to port over
my CSS, or I might not. I'll try to avoid needing custom versions
of ikiwiki's templates (if I can't, they'll need occasional
maintenance). At some point I'll decide my site looks good enough.

## Preserve feeds

Don't confuse aggregators. If ikiwiki's feed URLs will be different,
provide HTTP redirects for your subscribers.

Don't flood aggregators. If ikiwiki's article GUIDs will be different,
override the GUIDs of your most recent articles to match. I took
the permalinks and GUIDs from Textpattern's RSS feed (which are the
same as those for the Atom feed, I checked) and applied them to my
100 most recent posts (since that's the hardcoded maximum feed size
and I know I've got some subscribers to that).

Podcasts are feeds with enclosures. In addition to the above, take
care that the enclosure URLs don't change (or provide compatibility
redirects).

<http://ikiwiki.info/tips/migrating_podcast_to_ikiwiki/>

I could have set up a non-production instance of Textpattern,
subscribed to my podcasts, and migrated to a non-production instance
of ikiwiki. But I already tested that pretty well when I developed
ikiwiki's fancypodcast support.

Instead, I wrote automated tests (see `t/feedtests.t`) to compare
local copies of Textpattern's RSS and Atom feeds to each other,
Textpattern RSS to ikiwiki RSS, and Textpattern Atom to ikiwiki
Atom. Then I wrote `import-guids` to pull Textpattern's GUIDs (and
permalinks, for good measure) out of the feed and annotate the
corresponding ikiwiki posts with matching meta tags. Then I used
`git diff` to check my work and `git commit` when I was satisfied
with it -- exactly the sort of safety that reinforces my choice to
migrate to ikiwiki.

## Preserve other important URLs

I ran Analog over my webserver access log and looked at its "Request
Report" for frequently requested pages I completely forgot about.
Found some:

- Do care: my resume
    - `/resume` is redirecting to `/resume/amitai-schlair-resume.pdf`
- Do care: static files outside Textpattern
    - Anything in `/files/` I don't already have in `file_download`?
    - `/google315ed148ae7a1278.html` symlink (for Google Analytics?)
    - `/js/*` (I have no idea what this stuff is for)
    - `/keybase.txt` (for Keybase.io)
    - `/nottxp/*`
    - `/ppw2014/*` (a recent talk)
    - `/ssh-public-keys.txt` symlink
- Do care: podcast enclosures, specifically
    - In the CMS, you get a link to `/file_download/id/foo.mp3`
    - Then you get an HTTP redirect to `/files/foo.mp3`
    - And that's where the files are really stored
    - It would be nice to store the enclosures in `files`, as before
    - Can I do that without breaking existing feed enclosure URLs?
        - HTTP redirects from `file_download` wouldn't help ikiwiki
        - Symlinks from `file_download` might help ikiwiki
        - Maybe both together would work well
- Do care: custom RSS and Atom feeds
    - `limit=100`
    - `section=article`
    - `category=`(one for every category)
    - generate equivalent feeds somewhere, then HTTP redirect to them
- Do care: lists of articles by category, at `/category/[Ff]oo`
    - generate `/tag/foo` pages, then HTTP redirect to them
- Don't care: `/css.php?foo`

## Flip the switch

Stop the web server and rotate the logs:

    :myserver; cd logs
    :myserver; cp access access.textpattern && > access
    :myserver; cp errors errors.textpattern && > errors

Edit the server configuration to serve your ikiwiki `$DESTDIR`.

Start the server, watch the error log, and fix whatever's obviously
wrong.

-----

## After it's live

- Prepend "Yareev's schmonz.com: " to all page titles but the topmost
    - Patch `IkiWiki/Render.pm` around line 128
- Add myself to IkiWikiUsers!
- Git integration (and autocommit for tags, comments)
- Watch logs for 404s
- Crawl site for broken links
- Apply my (pending-review) patch for URLs in anonymous comments
    - `ikiwiki --rebuild`
- Apply my `wordcount` plugin for posts
- Convert `http://www.schmonz.com/...` references to relative WikiLinks
    - Likewise for `/...` references
    - But _not_ for links that turn into feed URLs, if there are any
    - meta permalink can be just /2014/foo
- Wherever I have HTTP redirects, make sure they're going to be countable
    - Try to have them not depend on webserver (someday, `bozohttpd`)
- Tag cloud (pagestats plugin), other cool tag stuff
- Convert Textile to Markdown, disable Textile input
- Stop accepting new comments after some time has passed? Only if spammy
- add_plugins:
    - blogspam
    - calendar
    - highlight (for OS X too)
    - moderatedcomments
- Comments on podcasts have a weird "download" link under the commentform
